{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PREPARACION DE DATOS PARA ENTRENAR MODELO**\n",
    "\n",
    "\n",
    "<img src=\"../Imagenes/machinelearning.jpg\" alt=\"Texto alternativo\" width=\"2100\" height=\"900\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar el data, anteriormente lo pasamos todo a numericas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resultados = pd.read_csv(\"../BASESDEDATOS/CSVs/LimpiezaEncoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resultado\n",
       "1    0.472937\n",
       "2    0.276119\n",
       "0    0.250944\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_resultados.Resultado.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Como vemos y como vimos en las gráficas en el EDA la distribución de nuestro target \"Resultado\" es desigual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Vamos aplicar un SMOTE para igualar las clases**\n",
    "\n",
    "\n",
    "<img src=\"../Imagenes/smote.jpg\" alt=\"Texto alternativo\" width=\"1800\" height=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resultado                               1.000000\n",
       "Rendimiento_Ranking_Visitante           0.134902\n",
       "Ranking_Visitante_Cuadrado              0.124404\n",
       "Diferencia_Ranking                      0.121173\n",
       "Rendimiento_Vistante                    0.119874\n",
       "Ranking_Visitante                       0.113164\n",
       "Diferencia_Puntos_Visitante             0.113122\n",
       "Diferencia_Puntos_Local                 0.113122\n",
       "Ratio_Goles_por_partido_Visitante       0.099270\n",
       "Posicion_Visitante                      0.097892\n",
       "Ratio_Jornada_Visitante                 0.097236\n",
       "Local_Es_Favorito                       0.095578\n",
       "Visitante_Es_Favorito                   0.095578\n",
       "Diferencia_Posicion                     0.095022\n",
       "Local_Es_Ofensivo                       0.086566\n",
       "Goles_Marcados_Visitante_Acumulados     0.078100\n",
       "Estado_Tabla_Visitante                  0.077862\n",
       "Goles_Acumulados_Visitantes             0.071794\n",
       "Puntos_Acumulados_Visitantes            0.070571\n",
       "Visitante_Es_Ofensivo                   0.070175\n",
       "Media_Goles_Visitante                   0.065184\n",
       "Visitante_Es_Defensivo                  0.062663\n",
       "Ranking_Local                           0.062014\n",
       "Ranking_Local_Cuadrado                  0.058872\n",
       "Rendimiento_Ranking_Local               0.054671\n",
       "Local_Es_Defensivo                      0.053609\n",
       "Rendimiento_Local                       0.046211\n",
       "Media_Goles_Local                       0.042945\n",
       "Posicion_Local                          0.037576\n",
       "Ratio_Jornada_Local                     0.036699\n",
       "Rendimiento_Fuera_Visitante             0.035371\n",
       "Ratio_Goles_por_partido_Local           0.031285\n",
       "Goles_Encajados_Visitante_Acumulados    0.028379\n",
       "Media_Goles                             0.026741\n",
       "Estado_Tabla_Local                      0.022256\n",
       "Goles_Encajados_Local_Acumulados        0.020257\n",
       "Racha_Visitante                         0.018996\n",
       "Racha_Puntos_Visitante                  0.017276\n",
       "Racha_Puntos_Local                      0.015221\n",
       "Puntos_Acumulados_Local                 0.014669\n",
       "Porterias_Cero_Visitante_Acum           0.014474\n",
       "Temporada                               0.013072\n",
       "Goles_Acumulados_Local                  0.011309\n",
       "Local                                   0.010747\n",
       "Goles_Marcados_Local_Acumulados         0.010467\n",
       "Jornada                                 0.009255\n",
       "Visitante                               0.009103\n",
       "Racha_Local                             0.007918\n",
       "Forma_Reciente_Visitante                0.007544\n",
       "Porterias_Cero_Local_Acum               0.005429\n",
       "Forma_Reciente_Local                    0.003697\n",
       "Rendimiento_Casa_Local                  0.000432\n",
       "Name: Resultado, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular la correlación de todas las columnas con 'Resultado'\n",
    "target_column = 'Resultado'\n",
    "correlation_with_target = abs(data_resultados.corr()[target_column])\n",
    "\n",
    "# Ordenar las correlaciones de mayor a menor\n",
    "correlation_with_target = correlation_with_target.sort_values(ascending=False)\n",
    "\n",
    "# Mostrar las correlaciones  #Algo de correlación hemos aumentado no mucho pero algo mejor.\n",
    "correlation_with_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_resultados.drop(columns=['Resultado'])\n",
    "y = data_resultados['Resultado']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Separación X_Train e Y_Train**\n",
    "\n",
    "\n",
    "<img src=\"../Imagenes/xtrain.jpg\" alt=\"Texto alternativo\" width=\"1400\" height=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE para balancear las clases\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Construcción de los modelos**\n",
    "\n",
    "\n",
    "<img src=\"../Imagenes/construccion.jpg\" alt=\"Texto alternativo\" width=\"1600\" height=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 1: Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Mejores parámetros: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.16      0.19       432\n",
      "           1       0.58      0.64      0.61       825\n",
      "           2       0.43      0.47      0.45       491\n",
      "\n",
      "    accuracy                           0.47      1748\n",
      "   macro avg       0.41      0.42      0.42      1748\n",
      "weighted avg       0.45      0.47      0.46      1748\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 69 209 154]\n",
      " [139 531 155]\n",
      " [ 83 178 230]]\n",
      "Accuracy: 0.4748283752860412\n",
      "Modelo guardado como best_log_model_3.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el modelo y los nuevos parámetros de GridSearch\n",
    "log_reg = LogisticRegression(max_iter=1000,class_weight='balanced', random_state=42)\n",
    "param_grid = [\n",
    "    {'C': [100], 'solver': ['liblinear'], 'penalty': ['l1', 'l2']},\n",
    "    {'C': [100], 'solver': ['saga'], 'penalty': ['l1', 'l2'], 'l1_ratio': [0, 0.5, 1]}\n",
    "]\n",
    "\n",
    "# Aplicar GridSearchCV\n",
    "grid_log_reg = GridSearchCV(log_reg, param_grid, cv=3, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
    "grid_log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_log_reg = grid_log_reg.best_estimator_\n",
    "y_pred_log_reg = best_log_reg.predict(X_test)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Mejores parámetros:\", grid_log_reg.best_params_)\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_log_reg))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "model_filename = 'best_log_model_3.joblib'\n",
    "dump(best_log_reg, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 2: Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Mejores parámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.28      0.27       432\n",
      "           1       0.51      0.48      0.49       825\n",
      "           2       0.33      0.34      0.34       491\n",
      "\n",
      "    accuracy                           0.39      1748\n",
      "   macro avg       0.37      0.37      0.37      1748\n",
      "weighted avg       0.40      0.39      0.39      1748\n",
      "\n",
      "Confusion Matrix:\n",
      "[[121 190 121]\n",
      " [206 393 226]\n",
      " [140 182 169]]\n",
      "Accuracy: 0.39073226544622425\n",
      "Modelo guardado como best_tree_model_3.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Definir el modelo y los nuevos parámetros de GridSearch\n",
    "decision_tree = DecisionTreeClassifier(class_weight='balanced',random_state=42)\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 8, 10, 12, 15],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Aplicar GridSearchCV\n",
    "grid_tree = GridSearchCV(decision_tree, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_tree = grid_tree.best_estimator_\n",
    "y_pred_tree = best_tree.predict(X_test)\n",
    "print(\"Decision Tree Classifier\")\n",
    "print(\"Mejores parámetros:\", grid_tree.best_params_)\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_tree))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tree))\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "model_filename = 'best_tree_model_3.joblib'\n",
    "dump(best_tree, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 3: Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier con RandomizedSearchCV\n",
      "Mejores parámetros: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 50, 'bootstrap': False}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.19      0.22       432\n",
      "           1       0.55      0.66      0.60       825\n",
      "           2       0.44      0.42      0.43       491\n",
      "\n",
      "    accuracy                           0.47      1748\n",
      "   macro avg       0.42      0.42      0.42      1748\n",
      "weighted avg       0.45      0.47      0.46      1748\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 82 237 113]\n",
      " [138 542 145]\n",
      " [ 79 207 205]]\n",
      "Accuracy: 0.4742562929061785\n",
      "Modelo guardado como best_forest_model_random_3.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definir el modelo y los parámetros de RandomizedSearch\n",
    "random_forest = RandomForestClassifier(class_weight='balanced',random_state=42)\n",
    "param_distributions = {\n",
    "    'n_estimators': [200, 300, 400, 500, 600],\n",
    "    'max_depth': [30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', 0.5],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Aplicar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(random_forest, param_distributions, n_iter=150, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_forest_random = random_search.best_estimator_\n",
    "y_pred_forest_random = best_forest_random.predict(X_test)\n",
    "print(\"Random Forest Classifier con RandomizedSearchCV\")\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred_forest_random))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_forest_random))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_forest_random))\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "model_filename = 'best_forest_model_random_3.joblib'\n",
    "dump(best_forest_random, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 4: Gradient Boosting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier con RandomizedSearchCV\n",
      "Mejores parámetros: {'n_estimators': 600, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'max_depth': 11, 'learning_rate': 0.2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.14      0.18       432\n",
      "           1       0.54      0.68      0.61       825\n",
      "           2       0.42      0.39      0.40       491\n",
      "\n",
      "    accuracy                           0.47      1748\n",
      "   macro avg       0.40      0.40      0.40      1748\n",
      "weighted avg       0.43      0.47      0.44      1748\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 61 253 118]\n",
      " [116 565 144]\n",
      " [ 79 222 190]]\n",
      "Accuracy: 0.4668192219679634\n",
      "Modelo guardado como best_gb_model_random_3.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Definir el modelo y los parámetros de RandomizedSearch\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "param_distributions = {\n",
    "    'n_estimators': [400,500,600],\n",
    "    'learning_rate': [0.2, 0.3,0.35,0.4],\n",
    "    'max_depth': [5,7,9,11],\n",
    "    'min_samples_split': [2, 5,7],\n",
    "    'min_samples_leaf': [6, 8,10,12],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Aplicar RandomizedSearchCV\n",
    "random_search_gb = RandomizedSearchCV(gradient_boosting, param_distributions, n_iter=50, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_gb_random = random_search_gb.best_estimator_\n",
    "y_pred_gb_random = best_gb_random.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier con RandomizedSearchCV\")\n",
    "print(\"Mejores parámetros:\", random_search_gb.best_params_)\n",
    "print(classification_report(y_test, y_pred_gb_random))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_gb_random))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb_random))\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "model_filename = 'best_gb_model_random_3.joblib'\n",
    "dump(best_gb_random, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 5: Support Vector Machine (SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raul_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 18 is smaller than n_iter=50. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine (SVM) con RandomizedSearchCV\n",
      "Mejores parámetros: {'kernel': 'rbf', 'gamma': 'auto', 'C': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.30      0.28       432\n",
      "           1       0.52      0.50      0.51       825\n",
      "           2       0.34      0.31      0.33       491\n",
      "\n",
      "    accuracy                           0.40      1748\n",
      "   macro avg       0.37      0.37      0.37      1748\n",
      "weighted avg       0.41      0.40      0.40      1748\n",
      "\n",
      "Confusion Matrix:\n",
      "[[131 190 111]\n",
      " [232 409 184]\n",
      " [150 187 154]]\n",
      "Accuracy: 0.39702517162471396\n",
      "Modelo guardado como best_svm_model_random_3.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Definir el modelo y los parámetros de RandomizedSearch\n",
    "svm_model = SVC(class_weight='balanced', probability=True,random_state=42)\n",
    "param_distributions = {\n",
    "    'C': [100,200,300],\n",
    "    'kernel': ['linear', 'rbf','sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "\n",
    "}\n",
    "\n",
    "# Aplicar RandomizedSearchCV\n",
    "random_search_svm = RandomizedSearchCV(svm_model, param_distributions, n_iter=50, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_svm_random = random_search_svm.best_estimator_\n",
    "y_pred_svm_random = best_svm_random.predict(X_test)\n",
    "print(\"Support Vector Machine (SVM) con RandomizedSearchCV\")\n",
    "print(\"Mejores parámetros:\", random_search_svm.best_params_)\n",
    "print(classification_report(y_test, y_pred_svm_random))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm_random))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm_random))\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "model_filename = 'best_svm_model_random_3.joblib'\n",
    "dump(best_svm_random, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 6: K-Nearest Neighbors (KNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors (KNN) con RandomizedSearchCV\n",
      "Mejores parámetros: {'weights': 'distance', 'n_neighbors': 3, 'metric': 'manhattan', 'leaf_size': 70, 'algorithm': 'auto'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.29      0.27       432\n",
      "           1       0.52      0.47      0.49       825\n",
      "           2       0.38      0.41      0.39       491\n",
      "\n",
      "    accuracy                           0.41      1748\n",
      "   macro avg       0.39      0.39      0.39      1748\n",
      "weighted avg       0.42      0.41      0.41      1748\n",
      "\n",
      "Confusion Matrix:\n",
      "[[124 188 120]\n",
      " [229 385 211]\n",
      " [127 163 201]]\n",
      "Accuracy: 0.4061784897025172\n",
      "Modelo guardado como best_knn_model_random_3.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Definir el modelo y los parámetros de RandomizedSearch\n",
    "knn_model = KNeighborsClassifier()\n",
    "param_distributions = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'algorithm': ['auto','kd_tree', 'brute'],\n",
    "    'leaf_size': [30, 40, 50,60,70]\n",
    "}\n",
    "\n",
    "# Aplicar RandomizedSearchCV\n",
    "random_search_knn = RandomizedSearchCV(knn_model, param_distributions, n_iter=300, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_knn_random = random_search_knn.best_estimator_\n",
    "y_pred_knn_random = best_knn_random.predict(X_test)\n",
    "print(\"K-Nearest Neighbors (KNN) con RandomizedSearchCV\")\n",
    "print(\"Mejores parámetros:\", random_search_knn.best_params_)\n",
    "print(classification_report(y_test, y_pred_knn_random))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn_random))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn_random))\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "model_filename = 'best_knn_model_random_3.joblib'\n",
    "dump(best_knn_random, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 7: Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes con GridSearchCV\n",
      "Mejores parámetros: {'var_smoothing': 0.04328761281083057}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.30      0.27       432\n",
      "           1       0.62      0.51      0.56       825\n",
      "           2       0.41      0.45      0.43       491\n",
      "\n",
      "    accuracy                           0.44      1748\n",
      "   macro avg       0.43      0.42      0.42      1748\n",
      "weighted avg       0.47      0.44      0.45      1748\n",
      "\n",
      "Confusion Matrix:\n",
      "[[131 147 154]\n",
      " [244 419 162]\n",
      " [160 110 221]]\n",
      "Accuracy: 0.44107551487414187\n",
      "Modelo guardado como best_naive_bayes_model_grid_3.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Definir el modelo y los parámetros de GridSearch\n",
    "naive_bayes = GaussianNB()\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(0, -9, num=100)\n",
    "}\n",
    "\n",
    "# Aplicar GridSearchCV\n",
    "grid_search_nb = GridSearchCV(naive_bayes, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_nb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_nb_grid = grid_search_nb.best_estimator_\n",
    "y_pred_nb_grid = best_nb_grid.predict(X_test)\n",
    "print(\"Naive Bayes con GridSearchCV\")\n",
    "print(\"Mejores parámetros:\", grid_search_nb.best_params_)\n",
    "print(classification_report(y_test, y_pred_nb_grid))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nb_grid))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb_grid))\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "model_filename = 'best_naive_bayes_model_grid_3.joblib'\n",
    "dump(best_nb_grid, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 8: XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raul_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [10:54:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost con RandomizedSearchCV\n",
      "Mejores parámetros: {'subsample': 0.8, 'n_estimators': 400, 'min_child_weight': 1, 'max_depth': 13, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.6}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.16      0.20       432\n",
      "           1       0.55      0.68      0.61       825\n",
      "           2       0.41      0.40      0.40       491\n",
      "\n",
      "    accuracy                           0.47      1748\n",
      "   macro avg       0.41      0.41      0.41      1748\n",
      "weighted avg       0.44      0.47      0.45      1748\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 71 241 120]\n",
      " [108 558 159]\n",
      " [ 89 207 195]]\n",
      "Accuracy: 0.47139588100686497\n",
      "Modelo guardado como best_xgb_model_random_3.joblib\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Definir el modelo y los parámetros de RandomizedSearch\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss',scale_pos_weight=1)\n",
    "param_distributions = {\n",
    "    'n_estimators': [300, 400, 500, 600],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [ 7, 9, 11, 13, 15],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.125, 0.2]\n",
    "}\n",
    "\n",
    "# Aplicar RandomizedSearchCV\n",
    "random_search_xgb = RandomizedSearchCV(xgb_model, param_distributions, n_iter=50, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_xgb_random = random_search_xgb.best_estimator_\n",
    "y_pred_xgb_random = best_xgb_random.predict(X_test)\n",
    "print(\"XGBoost con RandomizedSearchCV\")\n",
    "print(\"Mejores parámetros:\", random_search_xgb.best_params_)\n",
    "print(classification_report(y_test, y_pred_xgb_random))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb_random))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb_random))\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "model_filename = 'best_xgb_model_random_3.joblib'\n",
    "dump(best_xgb_random, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 9: Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier con RandomizedSearchCV\n",
      "Mejores parámetros: {'n_estimators': 300, 'max_samples': 1.0, 'max_features': 0.4, 'bootstrap_features': False, 'bootstrap': False}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.16      0.20       432\n",
      "           1       0.56      0.68      0.61       825\n",
      "           2       0.42      0.42      0.42       491\n",
      "\n",
      "    accuracy                           0.48      1748\n",
      "   macro avg       0.42      0.42      0.41      1748\n",
      "weighted avg       0.45      0.48      0.46      1748\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 69 240 123]\n",
      " [106 563 156]\n",
      " [ 76 209 206]]\n",
      "Accuracy: 0.4794050343249428\n",
      "Modelo guardado como best_bagging_model_random_3.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_model = BaggingClassifier( random_state=42)\n",
    "\n",
    "# Definir los parámetros para RandomizedSearch\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200,300,400],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.4, 0.5, 0.7, 1.0],\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "# Aplicar RandomizedSearchCV\n",
    "random_search_bagging = RandomizedSearchCV(bagging_model, param_distributions, n_iter=100, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search_bagging.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_bagging_random = random_search_bagging.best_estimator_\n",
    "y_pred_bagging_random = best_bagging_random.predict(X_test)\n",
    "print(\"Bagging Classifier con RandomizedSearchCV\")\n",
    "print(\"Mejores parámetros:\", random_search_bagging.best_params_)\n",
    "print(classification_report(y_test, y_pred_bagging_random))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_bagging_random))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_bagging_random))\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "model_filename = 'best_bagging_model_random_3.joblib'\n",
    "dump(best_bagging_random, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 10: LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7051\n",
      "[LightGBM] [Info] Number of data points in the train set: 9924, number of used features: 51\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Classifier con RandomizedSearchCV\n",
      "Mejores parámetros: {'objective': 'multiclass', 'num_leaves': 90, 'n_estimators': 600, 'max_depth': 40, 'learning_rate': 0.2, 'boosting_type': 'gbdt'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.15      0.18       432\n",
      "           1       0.55      0.67      0.60       825\n",
      "           2       0.40      0.38      0.39       491\n",
      "\n",
      "    accuracy                           0.46      1748\n",
      "   macro avg       0.40      0.40      0.39      1748\n",
      "weighted avg       0.43      0.46      0.44      1748\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 64 243 125]\n",
      " [116 556 153]\n",
      " [ 85 217 189]]\n",
      "Accuracy: 0.46281464530892447\n",
      "Modelo guardado como best_lgbm_model_random_3.joblib\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Definir el modelo y los parámetros de RandomizedSearch\n",
    "lgbm_model = LGBMClassifier(class_weight='balanced',random_state=42)\n",
    "param_distributions = {\n",
    "    'n_estimators': [400,500,600],\n",
    "    'learning_rate': [ 0.1, 0.2, 0.3],\n",
    "    'num_leaves': [31, 50, 70, 90],\n",
    "    'boosting_type': ['gbdt', 'dart'],\n",
    "    'objective': ['multiclass'],\n",
    "    'max_depth': [-1, 10, 20, 30 , 40]\n",
    "}\n",
    "\n",
    "# Aplicar RandomizedSearchCV\n",
    "random_search_lgbm = RandomizedSearchCV(lgbm_model, param_distributions, n_iter=100, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_lgbm = random_search_lgbm.best_estimator_\n",
    "y_pred_lgbm = best_lgbm.predict(X_test)\n",
    "print(\"LightGBM Classifier con RandomizedSearchCV\")\n",
    "print(\"Mejores parámetros:\", random_search_lgbm.best_params_)\n",
    "print(classification_report(y_test, y_pred_lgbm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lgbm))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lgbm))\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "model_filename = 'best_lgbm_model_random_3.joblib'\n",
    "dump(best_lgbm, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 11: CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raul_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=50. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Classifier con RandomizedSearchCV\n",
      "Mejores parámetros: {'learning_rate': 0.1, 'l2_leaf_reg': 3, 'iterations': 600, 'depth': 15, 'border_count': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.20      0.23       432\n",
      "           1       0.57      0.64      0.60       825\n",
      "           2       0.41      0.41      0.41       491\n",
      "\n",
      "    accuracy                           0.47      1748\n",
      "   macro avg       0.42      0.42      0.41      1748\n",
      "weighted avg       0.45      0.47      0.46      1748\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 87 219 126]\n",
      " [131 530 164]\n",
      " [106 183 202]]\n",
      "Accuracy: 0.4685354691075515\n",
      "Modelo guardado como best_catboost_model_random_3.joblib\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Definir el modelo de CatBoost\n",
    "catboost_model = CatBoostClassifier(auto_class_weights='Balanced', random_state=42, silent=True)\n",
    "\n",
    "# Definir los parámetros para RandomizedSearch\n",
    "param_distributions = {\n",
    "    'iterations': [500,600],\n",
    "    'learning_rate': [0.1],\n",
    "    'depth': [10,12,15],\n",
    "    'l2_leaf_reg': [3],\n",
    "    'border_count': [100]\n",
    "}\n",
    "\n",
    "# Aplicar RandomizedSearchCV\n",
    "random_search_catboost = RandomizedSearchCV(catboost_model, param_distributions, n_iter=50, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "random_search_catboost.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_catboost_random = random_search_catboost.best_estimator_\n",
    "y_pred_catboost_random = best_catboost_random.predict(X_test)\n",
    "print(\"CatBoost Classifier con RandomizedSearchCV\")\n",
    "print(\"Mejores parámetros:\", random_search_catboost.best_params_)\n",
    "print(classification_report(y_test, y_pred_catboost_random))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_catboost_random))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_catboost_random))\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "model_filename = 'best_catboost_model_random_3.joblib'\n",
    "dump(best_catboost_random, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AAAAAAAAAAAAAAAAA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mAAAAAAAAAAAAAAAAA\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AAAAAAAAAAAAAAAAA' is not defined"
     ]
    }
   ],
   "source": [
    "AAAAAAAAAAAAAAAAA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stacking de los modelos**\n",
    "\n",
    "\n",
    "<img src=\"../Imagenes/stacking.jpg\" alt=\"Texto alternativo\" width=\"1200\" height=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking con Meta modelo LogisticRegresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.20      0.24       432\n",
      "           1       0.54      0.67      0.60       825\n",
      "           2       0.43      0.38      0.40       491\n",
      "\n",
      "    accuracy                           0.47      1748\n",
      "   macro avg       0.42      0.42      0.42      1748\n",
      "weighted avg       0.45      0.47      0.46      1748\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 88 244 100]\n",
      " [123 555 147]\n",
      " [ 78 227 186]]\n",
      "Accuracy: 0.4742562929061785\n",
      "Modelo guardado como best_stacking_model_3.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "# Cargar los modelos guardados\n",
    "best_forest_stack = load('best_forest_model_random_3.joblib')\n",
    "best_gb_stack = load('best_gb_model_random_3.joblib')\n",
    "best_knn_stack = load('best_knn_model_random_3.joblib')\n",
    "best_xgb_stack = load('best_xgb_model_random_3.joblib')\n",
    "best_baggin_stack = load('best_bagging_model_random_3.joblib')\n",
    "best_log_stack = load('best_log_model_3.joblib')\n",
    "best_tree_stack = load('best_tree_model_3.joblib')\n",
    "best_svm_stack = load('best_svm_model_random_3.joblib')\n",
    "best_naive_stack = load('best_naive_bayes_model_grid_3.joblib')\n",
    "best_lgbm_stack = load('best_lgbm_model_random_3.joblib')\n",
    "best_cat_stack = load('best_catboost_model_random_3.joblib')\n",
    "\n",
    "# Definir el meta-modelo\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Crear el StackingClassifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('forest', best_forest_stack),\n",
    "        ('gb', best_gb_stack),\n",
    "        ('knn', best_knn_stack),\n",
    "        ('xgb', best_xgb_stack),\n",
    "        ('baggin', best_baggin_stack),\n",
    "        ('log', best_log_stack),\n",
    "        ('tree', best_tree_stack),\n",
    "        ('svm', best_svm_stack),\n",
    "        ('naive', best_naive_stack),\n",
    "        ('lgbm', best_lgbm_stack),\n",
    "        ('cat', best_cat_stack),\n",
    "    ],\n",
    "    final_estimator=meta_model,\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenar el meta-modelo\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el meta-modelo\n",
    "y_pred_stack = stacking_clf.predict(X_test)\n",
    "print(\"Stacking Classifier\")\n",
    "print(classification_report(y_test, y_pred_stack))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_stack))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_stack))\n",
    "\n",
    "# Guardar el meta-modelo\n",
    "model_filename = 'best_stacking_model_3.joblib'\n",
    "dump(stacking_clf, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAAAAAAAAAAAA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
